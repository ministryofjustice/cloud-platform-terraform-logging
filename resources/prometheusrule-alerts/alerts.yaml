---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: fluent-bit-errors
  namespace: logging
  labels:
    prometheus: cloud-platform
spec:
  groups:
  - name: fluentbit
    rules:
    - alert: FluentbitTooManyErrors
      expr: rate(fluentbit_output_retries_failed_total[10m]) > 10
      for: 10m
      labels:
        severity: warning
      annotations:
        message: Fluentbit is erroring. Check the logs.
    - alert: FluentbitChunkTooManyRetries
      expr: rate(fluentbit_output_retries_total[10m]) > 10
      for: 10m
      labels:
        severity: warning
      annotations:
        message: Fluentbit is attempting to retry flushing a chunk too many times, this is a sign fluent bit isn't processing logs correctly and could lead to log loss.
    - alert: FluentbitIsCrashLoopBackoffing
      expr: rate(kube_pod_container_status_restarts_total{job="kube-state-metrics",namespace="logging"}[15m]) * 60 * 15 > 0
      for: 10m
      labels:
        severity: warning
      annotations:
        message: A Fluentbit pod is CrashLoopBackOff'ing
    - alert: FluentbitIsOOMKilled
      expr: sum_over_time(kube_pod_container_status_last_terminated_reason{namespace='logging', container="fluent-bit", reason="OOMKilled"}[15m]) > 1
      for: 15m
      labels:
        severity: warning
      annotations:
        message: |
          A Fluentbit pod is OOMKilled. This alert works by watching for:

          ```
          Last State: Terminated
            Reason:       OOMKilled
          ```

          When you've fixed the issue, be sure to delete the pod manually to reset the last state and correctly resolve the alarm
